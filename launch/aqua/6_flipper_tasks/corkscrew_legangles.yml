output_directory: /localdata/robot_learning/

default_task_params: &default_task_params
  initial_random_trials: 1
  n_opt: 50
  horizon_secs: 20.0
  discount: 1.0
  angle_dims: &default_angle_dims [0, 1, 2]
  random_walk: False
  wrap_angles: True
  return_best: False
  n_samples: 100
  noisy_policy_input: True
  learning_rate: !numpy 1e-3
  # options for truncated backpropagation through time
  # split the horizon in split_H segments and, for each segment, remove
  # truncate_gradient time steps from the beginning of the sequence
  # (during the backwards pass)
  split_H: 1
  truncate_gradient: 0
  crn: 200
  mm_cost: True
  mm_state: True

default_policy_params: &default_policy_params
  input_dims: 7  # TODO, this should be inferred from data
  angle_dims: *default_angle_dims
  maxU: !numpy "[np.sqrt(np.pi/4)]*2 + [np.pi/2]*2"
  sat: !!python/name:kusanagi.ghost.control.saturation.tanhSat

default_bnn_params: &default_bnn_params
  # TODO, these dimensions should be inferred from data
  idims: 22 # non_angle_state_dims + 2*angle_state_dims + controls
  odims: 7 # state_dims
  max_evals: 2000 # max evals for optimizer (.train() method)

default_network_spec: &default_network_spec
  hidden_dims: !numpy '[200]*4'
  p: 0.1
  p_input: 0.0
  nonlinearities: !!python/name:kusanagi.ghost.regression.nonlinearities.rectify
  W_init: !!python/object/apply:lasagne.init.GlorotNormal {}
  dropout_class: !!python/name:kusanagi.ghost.regression.layers.DenseDropoutLayer
  build_fn: !!python/name:kusanagi.ghost.regression.dropout_mlp

default_plant: &default_plant_params
    dt: 0.5
    state0_dist: &state0_dist !!python/object/apply:kusanagi.utils.distributions.Gaussian
      kwds: &state0_dist_kwds
        mean: !numpy np.array([0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])
        cov: !numpy np.eye(7)*(0.25**2)
    name: 'AquaRobotEnv'

default_loss_graph: &default_loss_graph !!python/object/apply:functools.partial
  func_: &func_ !!python/name:kusanagi.shell.cost.distance_based_cost
  args: [*func_]
  kwds:  
    loss_func: !!python/name:kusanagi.shell.cost.quadratic_saturating_loss
    cw: 0.1
    expl: 0.0

default_loss_fn: &default_loss_fn !!python/object/apply:kusanagi.shell.cost.build_loss_func
  args: [*default_loss_graph]
  kwds: &default_loss_fn_params
    angle_dims: !!python/object/apply:theano.tensor.ivector ['angle_dims']
    target: !!python/object/apply:theano.tensor.vector ['target']
    Q: !!python/object/apply:theano.tensor.matrix ['Q']

default_Q: 
  angle: &angle_Q !numpy np.diag([1.0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) # Use this for angle-stabilization tasks
  roll: &rollrate_Q !numpy np.diag([1.0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0]) # Use this for fixed roll-rate tasks 

tasks:
  corkscrew:
    <<: *default_task_params
    cost:
      params: &cs_cost_params
        angle_dims: *default_angle_dims
        target: [0, 0, 0, 1.0, 0.7, 0, 0]
        Q: *rollrate_Q
      fn: &cs_cost !!python/object/apply:functools.partial
        args: [*default_loss_fn]
        kwds:
          <<: *cs_cost_params
      graph: !!python/object/apply:functools.partial
        args: [*default_loss_graph]
        kwds:
          <<: *default_loss_fn_params
          <<: *cs_cost_params
    policy: !!python/object/apply:kusanagi.ghost.control.NNPolicy
      kwds:
        <<: *default_policy_params
        network_spec:
          <<: *default_network_spec
    transition_model: !!python/object/apply:kusanagi.ghost.regression.BNN
      kwds:
        <<: *default_bnn_params
        network_spec:
          <<: *default_network_spec
          p_input: 0.1
          dropout_class: !!python/name:kusanagi.ghost.regression.layers.DenseLogNormalDropoutLayer
    plant:
      <<: *default_plant_params
      loss_func: *cs_cost
    optimizer: !!python/object/apply:kusanagi.ghost.optimizers.SGDOptimizer
        kwds:
          min_method: 'ADAM'
          max_evals: 400
